{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "913f26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f3f7353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from 'c:\\\\Users\\\\ic2594\\\\crypto\\\\AAA_Thursday1\\\\data\\\\__init__.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from __imports__ import *\n",
    "import data, LSTM_returns, optimization\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "398347ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ta  # pip install ta\n",
    "\n",
    "def compute_slope(series):\n",
    "    y = series.values\n",
    "    x = np.arange(len(y))\n",
    "    if len(y) == 0:\n",
    "        return np.nan\n",
    "    return np.polyfit(x, y, 1)[0]\n",
    "\n",
    "def add_technical_features(df, look_back=14):\n",
    "    df = df.copy()  \n",
    "    df['Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['Risk'] = df['Return'].rolling(window=look_back).std()\n",
    "    df['RSI'] = ta.momentum.RSIIndicator(close=df['Close'], window=look_back).rsi()\n",
    "    df['ADX'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=look_back).adx()\n",
    "    df['MOM'] = df['Close'] - df['Close'].shift(look_back)\n",
    "    df['HL'] = df['High'] - df['Low']\n",
    "    df['HO'] = df['High'] - df['Open']\n",
    "    df['LO'] = df['Low'] - df['Open']\n",
    "    df['buy_pressure_ratio'] = df['Taker buy quote asset volume'] / df['Quote asset volume']\n",
    "    df['trades_per_volume'] = df['Number of trades'] / df['Quote asset volume']\n",
    "    df['slope'] = df['Close'].rolling(window=look_back).apply(compute_slope, raw=False)\n",
    "    df = df.dropna()\n",
    "    cols_to_drop = [\n",
    "        'Open', 'High', 'Low', 'Quote asset volume',\n",
    "        'Number of trades', 'Taker buy base asset volume',\n",
    "        'Taker buy quote asset volume', 'F&G'\n",
    "    ]\n",
    "    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "    return df\n",
    "\n",
    "def prep_data(df, sequence_length=60, test_size=0.2, num_folds=4):\n",
    "    # 1) include 'Close' since that's what we'll predict\n",
    "    features = [\n",
    "        'Close',      # ← our prediction target\n",
    "        'Volume', 'F&G category', 'Return', 'Risk', 'RSI', 'ADX',\n",
    "        'MOM', 'HL', 'HO', 'LO',\n",
    "        'buy_pressure_ratio', 'trades_per_volume', 'slope'\n",
    "    ]\n",
    "    \n",
    "    num_feats = [f for f in features if f != 'F&G category']\n",
    "    df_num = df[num_feats]\n",
    "    df_cat = pd.get_dummies(df['F&G category'], prefix='F_G')\n",
    "    \n",
    "    df_all = pd.concat([df_num, df_cat], axis=1).dropna()\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(df_all.values)\n",
    "    feature_names = df_all.columns.tolist()\n",
    "    \n",
    "    target_idx = feature_names.index('Close')\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data_scaled)):\n",
    "        X.append(data_scaled[i-sequence_length:i])\n",
    "        # y is the scaled Close price at time i (next day)\n",
    "        y.append(data_scaled[i, target_idx])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split into folds\n",
    "    fold_size = int(len(X) * (1 - test_size) / (num_folds + 1))\n",
    "    folds = []\n",
    "    for i in range(num_folds):\n",
    "        start_idx = i * fold_size\n",
    "        end_idx = start_idx + fold_size\n",
    "        X_train = X[:end_idx]\n",
    "        y_train = y[:end_idx]\n",
    "        X_test = X[end_idx:end_idx + fold_size]\n",
    "        y_test = y[end_idx:end_idx + fold_size]\n",
    "        folds.append((X_train, X_test, y_train, y_test))\n",
    "    \n",
    "    # Final test set (last 20% of the data)\n",
    "    final_test_idx = int(len(X) * (1 - test_size))\n",
    "    X_final_test = X[final_test_idx:]\n",
    "    y_final_test = y[final_test_idx:]\n",
    "    \n",
    "    return folds, (X_final_test, y_final_test), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2586155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "\n",
    "# ——— Hyperparameters (from Optuna) ———\n",
    "UNITS_L0      = 160\n",
    "DROPOUT_L0    = 0.0\n",
    "LEARNING_RATE = 0.0007280355873484089\n",
    "OPTIMIZER     = Adam(learning_rate=LEARNING_RATE)\n",
    "BATCH_SIZE    = 32\n",
    "MAX_EPOCHS    = 50\n",
    "\n",
    "def train_lstm_for_asset(prepped_data, test_size=0.2):\n",
    "    # … prep_data as before …\n",
    "    (X_train, X_val, y_train, y_val), scaler = prepped_data\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Input(shape=X_train.shape[1:]),\n",
    "        LSTM(UNITS_L0, return_sequences=False, dropout=DROPOUT_L0),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    # *** instantiate a new optimizer here, not reuse a global one ***\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    # Train\n",
    "    es = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=MAX_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[es],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, scaler, history, (X_val, y_val)\n",
    "\n",
    "\n",
    "def objective(trial, fold_number):\n",
    "    # Suggest hyperparameters\n",
    "    units_l0 = trial.suggest_int('units_l0', 50, 200)\n",
    "    dropout_l0 = trial.suggest_float('dropout_l0', 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    max_epochs = trial.suggest_int('max_epochs', 10, 100)\n",
    "\n",
    "    # Update global variables (if needed)\n",
    "    global UNITS_L0, DROPOUT_L0, LEARNING_RATE, BATCH_SIZE, MAX_EPOCHS\n",
    "    UNITS_L0 = units_l0\n",
    "    DROPOUT_L0 = dropout_l0\n",
    "    LEARNING_RATE = learning_rate\n",
    "    BATCH_SIZE = batch_size\n",
    "    MAX_EPOCHS = max_epochs\n",
    "\n",
    "    # Train the model\n",
    "    folds, (X_final_test, y_final_test), scaler = prep_data(df, sequence_length=30, test_size=0.2, num_folds=4)\n",
    "    \n",
    "    # Use walkforward folds for training and validation\n",
    "    rmse_scores = []\n",
    "    for fold_idx, (X_train, X_val, y_train, y_val) in enumerate(folds):\n",
    "        model, scaler, history, (X_val, y_val) = train_lstm_for_asset(((X_train, X_val, y_train, y_val), scaler))\n",
    "        preds = model.predict(X_val).flatten()\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    print(f\"MSE_SCORES: {rmse_scores}\")\n",
    "    \n",
    "    # Return the average RMSE across folds\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "\n",
    "# Example usage for any asset DataFrame `asset_df`:\n",
    "# model, scaler, history, (X_val, y_val) = train_lstm_for_asset(asset_df)\n",
    "\n",
    "# And to plot predictions vs actual:\n",
    "# preds = model.predict(X_val).flatten()\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.plot(y_val,  label='Actual Close (scaled)')\n",
    "# plt.plot(preds, label='Predicted Close (scaled)')\n",
    "# plt.legend()\n",
    "# plt.title(\"LSTM Forecast (Scaled)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebfb5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "class EarlyStoppingException(Exception):\n",
    "    pass\n",
    "\n",
    "# 1. Ensure eager mode for compatibility (if you set run_eagerly earlier)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# 2. Directories to save models and scalers\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('scalers', exist_ok=True)\n",
    "\n",
    "# 3. List of asset tickers\n",
    "assets = ['SOLUSDT', 'BTCUSDT', 'ETHUSDT', 'DOGEUSDT', 'XRPUSDT']\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03cad810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:48:30,771] A new study created in memory with name: no-name-e897f123-5754-45f1-a004-1369620cedc4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGINEERING SOLUSDT\n",
      "Epoch 1/38\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.1731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - loss: 0.1032 - val_loss: 0.1727\n",
      "Epoch 2/38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - loss: 0.0236 - val_loss: 0.0345\n",
      "Epoch 3/38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - loss: 0.0298 - val_loss: 0.0682\n",
      "Epoch 4/38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - loss: 0.0134 - val_loss: 0.1351\n",
      "Epoch 5/38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - loss: 0.0203 - val_loss: 0.0906\n",
      "Epoch 6/38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.0104 - val_loss: 0.0466\n",
      "Epoch 7/38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.0137 - val_loss: 0.0545\n",
      "Epoch 8/38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.0108 - val_loss: 0.0829\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Epoch 1/38\n",
      "\u001b[1m2/7\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1094 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0771 - val_loss: 0.0042\n",
      "Epoch 2/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0267 - val_loss: 0.0531\n",
      "Epoch 3/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0209 - val_loss: 0.0027\n",
      "Epoch 4/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 5/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0155 - val_loss: 0.0071\n",
      "Epoch 6/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0137 - val_loss: 0.0187\n",
      "Epoch 7/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0160 - val_loss: 0.0092\n",
      "Epoch 8/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0106 - val_loss: 0.0024\n",
      "Epoch 9/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0090 - val_loss: 0.0108\n",
      "Epoch 10/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0118 - val_loss: 0.0066\n",
      "Epoch 11/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 12/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0108 - val_loss: 0.0036\n",
      "Epoch 13/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 14/38\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0083 - val_loss: 0.0055\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 1/38\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.2250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0968 - val_loss: 0.0196\n",
      "Epoch 2/38\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0179 - val_loss: 0.0531\n",
      "Epoch 3/38\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0122 - val_loss: 0.0585\n",
      "Epoch 4/38\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0132 - val_loss: 0.0354\n",
      "Epoch 5/38\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0102 - val_loss: 0.0546\n",
      "Epoch 6/38\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0088 - val_loss: 0.0755\n",
      "Epoch 7/38\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0102 - val_loss: 0.0657\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Epoch 1/38\n",
      "\u001b[1m 2/14\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0706 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0450 - val_loss: 0.0017\n",
      "Epoch 2/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0162 - val_loss: 6.7821e-04\n",
      "Epoch 3/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0081 - val_loss: 5.4644e-04\n",
      "Epoch 4/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 5/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0103 - val_loss: 0.0032\n",
      "Epoch 6/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0087 - val_loss: 7.4548e-04\n",
      "Epoch 7/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0072 - val_loss: 0.0011\n",
      "Epoch 8/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 9/38\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0076 - val_loss: 6.7603e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:49:09,082] Trial 0 finished with value: 0.09958891145711263 and parameters: {'units_l0': 146, 'dropout_l0': 0.2853871764335532, 'learning_rate': 0.0011096139788511037, 'batch_size': 32, 'max_epochs': 38}. Best is trial 0 with value: 0.09958891145711263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.18575781724596918), np.float64(0.04930453224895738), np.float64(0.13991717327682432), np.float64(0.0233761230566997)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/74\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.5537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 0.5659 - val_loss: 0.0875\n",
      "Epoch 2/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.4791 - val_loss: 0.0568\n",
      "Epoch 3/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.3923 - val_loss: 0.0329\n",
      "Epoch 4/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 0.3401 - val_loss: 0.0159\n",
      "Epoch 5/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.2666 - val_loss: 0.0057\n",
      "Epoch 6/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.2111 - val_loss: 0.0021\n",
      "Epoch 7/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.1590 - val_loss: 0.0048\n",
      "Epoch 8/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 0.1163 - val_loss: 0.0136\n",
      "Epoch 9/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 0.0886 - val_loss: 0.0278\n",
      "Epoch 10/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.0659 - val_loss: 0.0469\n",
      "Epoch 11/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.0562 - val_loss: 0.0701\n",
      "Epoch 12/74\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.0390 - val_loss: 0.0956\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Epoch 1/74\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - loss: 0.1663 - val_loss: 0.0144\n",
      "Epoch 2/74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.0929 - val_loss: 0.0141\n",
      "Epoch 3/74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 0.0555 - val_loss: 0.0321\n",
      "Epoch 4/74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0424 - val_loss: 0.0566\n",
      "Epoch 5/74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0317 - val_loss: 0.0744\n",
      "Epoch 6/74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0371 - val_loss: 0.0771\n",
      "Epoch 7/74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - loss: 0.0397 - val_loss: 0.0659\n",
      "Epoch 8/74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 0.0310 - val_loss: 0.0497\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Epoch 1/74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 290ms/step - loss: 0.1127 - val_loss: 0.0273\n",
      "Epoch 2/74\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - loss: 0.0689 - val_loss: 0.0764\n",
      "Epoch 3/74\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - loss: 0.0468 - val_loss: 0.0986\n",
      "Epoch 4/74\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 262ms/step - loss: 0.0436 - val_loss: 0.0921\n",
      "Epoch 5/74\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 298ms/step - loss: 0.0381 - val_loss: 0.0708\n",
      "Epoch 6/74\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 282ms/step - loss: 0.0328 - val_loss: 0.0587\n",
      "Epoch 7/74\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 290ms/step - loss: 0.0250 - val_loss: 0.0576\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Epoch 1/74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 297ms/step - loss: 0.0444 - val_loss: 0.0101\n",
      "Epoch 2/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - loss: 0.0312 - val_loss: 0.0203\n",
      "Epoch 3/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 297ms/step - loss: 0.0280 - val_loss: 0.0098\n",
      "Epoch 4/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 289ms/step - loss: 0.0229 - val_loss: 0.0050\n",
      "Epoch 5/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step - loss: 0.0197 - val_loss: 0.0066\n",
      "Epoch 6/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 285ms/step - loss: 0.0176 - val_loss: 0.0091\n",
      "Epoch 7/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 272ms/step - loss: 0.0156 - val_loss: 0.0075\n",
      "Epoch 8/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - loss: 0.0134 - val_loss: 0.0065\n",
      "Epoch 9/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - loss: 0.0143 - val_loss: 0.0074\n",
      "Epoch 10/74\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 284ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:49:56,898] Trial 1 finished with value: 0.10000009378224611 and parameters: {'units_l0': 189, 'dropout_l0': 0.3386583496183564, 'learning_rate': 7.31413563089297e-05, 'batch_size': 64, 'max_epochs': 74}. Best is trial 0 with value: 0.09958891145711263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.045715641847464523), np.float64(0.11855241562830889), np.float64(0.16516747190488268), np.float64(0.0705648457483283)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/49\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.4727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.4963 - val_loss: 0.1615\n",
      "Epoch 2/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.5198 - val_loss: 0.1555\n",
      "Epoch 3/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.5070 - val_loss: 0.1495\n",
      "Epoch 4/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.4798 - val_loss: 0.1437\n",
      "Epoch 5/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.4535 - val_loss: 0.1381\n",
      "Epoch 6/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.4557 - val_loss: 0.1326\n",
      "Epoch 7/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.4605 - val_loss: 0.1273\n",
      "Epoch 8/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.4243 - val_loss: 0.1221\n",
      "Epoch 9/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.3897 - val_loss: 0.1172\n",
      "Epoch 10/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.4312 - val_loss: 0.1123\n",
      "Epoch 11/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.4071 - val_loss: 0.1075\n",
      "Epoch 12/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.4235 - val_loss: 0.1027\n",
      "Epoch 13/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - loss: 0.4262 - val_loss: 0.0980\n",
      "Epoch 14/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.4028 - val_loss: 0.0935\n",
      "Epoch 15/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.3836 - val_loss: 0.0892\n",
      "Epoch 16/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.3889 - val_loss: 0.0851\n",
      "Epoch 17/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.3527 - val_loss: 0.0810\n",
      "Epoch 18/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.3690 - val_loss: 0.0770\n",
      "Epoch 19/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - loss: 0.3531 - val_loss: 0.0732\n",
      "Epoch 20/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.3328 - val_loss: 0.0695\n",
      "Epoch 21/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.3340 - val_loss: 0.0659\n",
      "Epoch 22/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.3255 - val_loss: 0.0625\n",
      "Epoch 23/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.3115 - val_loss: 0.0591\n",
      "Epoch 24/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.2925 - val_loss: 0.0559\n",
      "Epoch 25/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.2952 - val_loss: 0.0528\n",
      "Epoch 26/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.2942 - val_loss: 0.0498\n",
      "Epoch 27/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - loss: 0.2910 - val_loss: 0.0469\n",
      "Epoch 28/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - loss: 0.2783 - val_loss: 0.0441\n",
      "Epoch 29/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2845 - val_loss: 0.0414\n",
      "Epoch 30/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2615 - val_loss: 0.0387\n",
      "Epoch 31/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.2438 - val_loss: 0.0362\n",
      "Epoch 32/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2647 - val_loss: 0.0339\n",
      "Epoch 33/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2662 - val_loss: 0.0316\n",
      "Epoch 34/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.2308 - val_loss: 0.0294\n",
      "Epoch 35/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - loss: 0.2375 - val_loss: 0.0273\n",
      "Epoch 36/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.2146 - val_loss: 0.0252\n",
      "Epoch 37/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - loss: 0.2159 - val_loss: 0.0233\n",
      "Epoch 38/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.2150 - val_loss: 0.0215\n",
      "Epoch 39/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - loss: 0.2287 - val_loss: 0.0197\n",
      "Epoch 40/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.2043 - val_loss: 0.0180\n",
      "Epoch 41/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.1901 - val_loss: 0.0165\n",
      "Epoch 42/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.1962 - val_loss: 0.0150\n",
      "Epoch 43/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1840 - val_loss: 0.0136\n",
      "Epoch 44/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.1845 - val_loss: 0.0122\n",
      "Epoch 45/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1737 - val_loss: 0.0110\n",
      "Epoch 46/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1676 - val_loss: 0.0098\n",
      "Epoch 47/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1736 - val_loss: 0.0087\n",
      "Epoch 48/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - loss: 0.1749 - val_loss: 0.0077\n",
      "Epoch 49/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1688 - val_loss: 0.0068\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Epoch 1/49\n",
      "\u001b[1m2/7\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1045 - val_loss: 0.0192\n",
      "Epoch 2/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1244 - val_loss: 0.0205\n",
      "Epoch 3/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1048 - val_loss: 0.0219\n",
      "Epoch 4/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1102 - val_loss: 0.0234\n",
      "Epoch 5/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0815 - val_loss: 0.0251\n",
      "Epoch 6/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0911 - val_loss: 0.0270\n",
      "Epoch 7/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0789 - val_loss: 0.0291\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Epoch 1/49\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0581 - val_loss: 0.1120\n",
      "Epoch 2/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0555 - val_loss: 0.1050\n",
      "Epoch 3/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0715 - val_loss: 0.0972\n",
      "Epoch 4/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0559 - val_loss: 0.0916\n",
      "Epoch 5/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0553 - val_loss: 0.0875\n",
      "Epoch 6/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0462 - val_loss: 0.0847\n",
      "Epoch 7/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0496 - val_loss: 0.0822\n",
      "Epoch 8/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0491 - val_loss: 0.0796\n",
      "Epoch 9/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0395 - val_loss: 0.0785\n",
      "Epoch 10/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0494 - val_loss: 0.0778\n",
      "Epoch 11/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0449 - val_loss: 0.0767\n",
      "Epoch 12/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0453 - val_loss: 0.0767\n",
      "Epoch 13/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0389 - val_loss: 0.0770\n",
      "Epoch 14/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0378 - val_loss: 0.0761\n",
      "Epoch 15/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0395 - val_loss: 0.0751\n",
      "Epoch 16/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0401 - val_loss: 0.0733\n",
      "Epoch 17/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0356 - val_loss: 0.0728\n",
      "Epoch 18/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0448 - val_loss: 0.0732\n",
      "Epoch 19/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0415 - val_loss: 0.0717\n",
      "Epoch 20/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - loss: 0.0376 - val_loss: 0.0708\n",
      "Epoch 21/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0391 - val_loss: 0.0697\n",
      "Epoch 22/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - loss: 0.0307 - val_loss: 0.0706\n",
      "Epoch 23/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0376 - val_loss: 0.0702\n",
      "Epoch 24/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0351 - val_loss: 0.0706\n",
      "Epoch 25/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - loss: 0.0305 - val_loss: 0.0707\n",
      "Epoch 26/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0332 - val_loss: 0.0708\n",
      "Epoch 27/49\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0320 - val_loss: 0.0707\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/49\n",
      "\u001b[1m 2/14\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0918 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0860 - val_loss: 0.0025\n",
      "Epoch 2/49\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0814 - val_loss: 0.0039\n",
      "Epoch 3/49\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0729 - val_loss: 0.0055\n",
      "Epoch 4/49\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0692 - val_loss: 0.0074\n",
      "Epoch 5/49\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0757 - val_loss: 0.0091\n",
      "Epoch 6/49\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0608 - val_loss: 0.0109\n",
      "Epoch 7/49\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0671 - val_loss: 0.0127\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:51:21,633] Trial 2 finished with value: 0.13376029288186336 and parameters: {'units_l0': 86, 'dropout_l0': 0.43132675183598096, 'learning_rate': 1.0142186732728418e-05, 'batch_size': 32, 'max_epochs': 49}. Best is trial 0 with value: 0.09958891145711263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.08231124680894271), np.float64(0.138739693909027), np.float64(0.2641011657285288), np.float64(0.04988906508095496)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/78\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0715 - val_loss: 0.1546\n",
      "Epoch 2/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0281 - val_loss: 0.1591\n",
      "Epoch 3/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0219 - val_loss: 0.0623\n",
      "Epoch 4/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0199 - val_loss: 0.0562\n",
      "Epoch 5/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0170 - val_loss: 0.0917\n",
      "Epoch 6/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0135 - val_loss: 0.0876\n",
      "Epoch 7/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0134 - val_loss: 0.0756\n",
      "Epoch 8/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0109 - val_loss: 0.0662\n",
      "Epoch 9/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0134 - val_loss: 0.0819\n",
      "Epoch 10/78\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0104 - val_loss: 0.0786\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Epoch 1/78\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.2174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1333 - val_loss: 0.1581\n",
      "Epoch 2/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0489 - val_loss: 0.0533\n",
      "Epoch 3/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0292 - val_loss: 0.0419\n",
      "Epoch 4/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0204 - val_loss: 0.0265\n",
      "Epoch 5/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0140 - val_loss: 0.0179\n",
      "Epoch 6/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0132 - val_loss: 0.0063\n",
      "Epoch 7/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 8/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0081 - val_loss: 0.0058\n",
      "Epoch 9/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 10/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 11/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 12/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0101 - val_loss: 0.0031\n",
      "Epoch 13/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 14/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 15/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0067 - val_loss: 0.0024\n",
      "Epoch 16/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0072 - val_loss: 0.0029\n",
      "Epoch 17/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0102 - val_loss: 0.0017\n",
      "Epoch 18/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 19/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 20/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 21/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0069 - val_loss: 0.0017\n",
      "Epoch 22/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 23/78\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0061 - val_loss: 0.0019\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/78\n",
      "\u001b[1m 2/21\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0495 - val_loss: 0.0221\n",
      "Epoch 2/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0165 - val_loss: 0.0283\n",
      "Epoch 3/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0079 - val_loss: 0.0195\n",
      "Epoch 4/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 5/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0094 - val_loss: 0.0461\n",
      "Epoch 6/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0061 - val_loss: 0.0585\n",
      "Epoch 7/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0069 - val_loss: 0.0489\n",
      "Epoch 8/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0070 - val_loss: 0.0516\n",
      "Epoch 9/78\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0064 - val_loss: 0.0598\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Epoch 1/78\n",
      "\u001b[1m 1/28\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.1057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0620 - val_loss: 0.0097\n",
      "Epoch 2/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0170 - val_loss: 0.0041\n",
      "Epoch 3/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0079 - val_loss: 0.0029\n",
      "Epoch 4/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0074 - val_loss: 0.0015\n",
      "Epoch 5/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0074 - val_loss: 0.0015\n",
      "Epoch 6/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0074 - val_loss: 5.6263e-04\n",
      "Epoch 7/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0071 - val_loss: 0.0011\n",
      "Epoch 8/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0065 - val_loss: 3.3837e-04\n",
      "Epoch 9/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 10/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 11/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - loss: 0.0047 - val_loss: 4.3690e-04\n",
      "Epoch 12/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - loss: 0.0069 - val_loss: 6.5643e-04\n",
      "Epoch 13/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 14/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 0.0053 - val_loss: 3.2559e-04\n",
      "Epoch 15/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - loss: 0.0070 - val_loss: 6.2896e-04\n",
      "Epoch 16/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0059 - val_loss: 0.0012\n",
      "Epoch 17/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0048 - val_loss: 4.0389e-04\n",
      "Epoch 18/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0048 - val_loss: 5.3328e-04\n",
      "Epoch 19/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0050 - val_loss: 3.3412e-04\n",
      "Epoch 20/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0046 - val_loss: 1.3292e-04\n",
      "Epoch 21/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0050 - val_loss: 5.6364e-04\n",
      "Epoch 22/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0026 - val_loss: 4.0654e-04\n",
      "Epoch 23/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0039 - val_loss: 4.1183e-04\n",
      "Epoch 24/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0035 - val_loss: 5.6317e-04\n",
      "Epoch 25/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0042 - val_loss: 1.7012e-04\n",
      "Epoch 26/78\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0032 - val_loss: 2.3046e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:53:57,792] Trial 3 finished with value: 0.10718230720086615 and parameters: {'units_l0': 98, 'dropout_l0': 0.1435205140721718, 'learning_rate': 0.000235526692390196, 'batch_size': 16, 'max_epochs': 78}. Best is trial 0 with value: 0.09958891145711263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.23701275210633582), np.float64(0.04068013776043767), np.float64(0.13950743924673148), np.float64(0.011528899689959628)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.1251 - val_loss: 0.0480\n",
      "Epoch 2/71\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - loss: 0.0183 - val_loss: 0.0245\n",
      "Epoch 3/71\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0232 - val_loss: 0.0916\n",
      "Epoch 4/71\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0136 - val_loss: 0.0605\n",
      "Epoch 5/71\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0121 - val_loss: 0.0847\n",
      "Epoch 6/71\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0108 - val_loss: 0.0593\n",
      "Epoch 7/71\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0080 - val_loss: 0.0771\n",
      "Epoch 8/71\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0091 - val_loss: 0.0618\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Epoch 1/71\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.1380 - val_loss: 0.0342\n",
      "Epoch 2/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 3/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0210 - val_loss: 0.0145\n",
      "Epoch 4/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 5/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.0197 - val_loss: 0.0168\n",
      "Epoch 6/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 7/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.0126 - val_loss: 0.0228\n",
      "Epoch 8/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0108 - val_loss: 0.0220\n",
      "Epoch 9/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0138 - val_loss: 0.0200\n",
      "Epoch 10/71\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0119 - val_loss: 0.0336\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 1/71\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.1392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0672 - val_loss: 0.0551\n",
      "Epoch 2/71\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0168 - val_loss: 0.0444\n",
      "Epoch 3/71\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0111 - val_loss: 0.0526\n",
      "Epoch 4/71\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0102 - val_loss: 0.1345\n",
      "Epoch 5/71\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 0.0125 - val_loss: 0.0956\n",
      "Epoch 6/71\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0119 - val_loss: 0.1569\n",
      "Epoch 7/71\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0128 - val_loss: 0.2725\n",
      "Epoch 8/71\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0093 - val_loss: 0.2468\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Epoch 1/71\n",
      "\u001b[1m 1/28\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.0623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0911 - val_loss: 0.0011\n",
      "Epoch 2/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0147 - val_loss: 0.0054\n",
      "Epoch 3/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0136 - val_loss: 0.0031\n",
      "Epoch 4/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0109 - val_loss: 0.0024\n",
      "Epoch 5/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0114 - val_loss: 6.3273e-04\n",
      "Epoch 6/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0114 - val_loss: 0.0011\n",
      "Epoch 7/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0120 - val_loss: 5.3592e-04\n",
      "Epoch 8/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0120 - val_loss: 0.0017\n",
      "Epoch 9/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0098 - val_loss: 0.0010\n",
      "Epoch 10/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0077 - val_loss: 3.0027e-04\n",
      "Epoch 11/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0126 - val_loss: 0.0015\n",
      "Epoch 12/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0057 - val_loss: 5.1131e-04\n",
      "Epoch 13/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0083 - val_loss: 3.3733e-04\n",
      "Epoch 14/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0080 - val_loss: 3.2168e-04\n",
      "Epoch 15/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0072 - val_loss: 3.4660e-04\n",
      "Epoch 16/71\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0088 - val_loss: 0.0030\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:55:19,208] Trial 4 finished with value: 0.12465620135277546 and parameters: {'units_l0': 160, 'dropout_l0': 0.35306734647465066, 'learning_rate': 0.0022051488168066346, 'batch_size': 16, 'max_epochs': 71}. Best is trial 0 with value: 0.09958891145711263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.15656547093824572), np.float64(0.11394991556422622), np.float64(0.21078116071133243), np.float64(0.017328258197297497)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/55\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2429 - val_loss: 0.1264\n",
      "Epoch 2/55\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0179 - val_loss: 0.0381\n",
      "Epoch 3/55\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0138 - val_loss: 0.0853\n",
      "Epoch 4/55\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0061 - val_loss: 0.0819\n",
      "Epoch 5/55\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0069 - val_loss: 0.0581\n",
      "Epoch 6/55\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0056 - val_loss: 0.0809\n",
      "Epoch 7/55\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0060 - val_loss: 0.0593\n",
      "Epoch 8/55\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0063 - val_loss: 0.0624\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Epoch 1/55\n",
      "\u001b[1m 2/14\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4261 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.2229 - val_loss: 0.0274\n",
      "Epoch 2/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 0.0152 - val_loss: 0.0087\n",
      "Epoch 3/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 4/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 5/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - loss: 0.0077 - val_loss: 0.0037\n",
      "Epoch 6/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 7/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 8/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 9/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 10/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 11/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 12/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 13/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 14/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 15/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 16/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 17/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 18/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 19/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 20/55\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - loss: 0.0048 - val_loss: 0.0024\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Epoch 1/55\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.3614 - val_loss: 0.0150\n",
      "Epoch 2/55\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0144 - val_loss: 0.0453\n",
      "Epoch 3/55\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0061 - val_loss: 0.0486\n",
      "Epoch 4/55\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0064 - val_loss: 0.0461\n",
      "Epoch 5/55\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0061 - val_loss: 0.0942\n",
      "Epoch 6/55\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0047 - val_loss: 0.0978\n",
      "Epoch 7/55\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0029 - val_loss: 0.1851\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Epoch 1/55\n",
      "\u001b[1m 1/28\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.2264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.2072 - val_loss: 0.0062\n",
      "Epoch 2/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0089 - val_loss: 0.0016\n",
      "Epoch 3/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0059 - val_loss: 3.4054e-04\n",
      "Epoch 4/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0047 - val_loss: 2.9239e-04\n",
      "Epoch 5/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 6/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0046 - val_loss: 1.9775e-04\n",
      "Epoch 7/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0051 - val_loss: 0.0011\n",
      "Epoch 8/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0041 - val_loss: 3.9894e-04\n",
      "Epoch 9/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0041 - val_loss: 7.5902e-04\n",
      "Epoch 10/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 11/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0053 - val_loss: 0.0011\n",
      "Epoch 12/55\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0042 - val_loss: 2.3263e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:56:44,278] Trial 5 finished with value: 0.09154226717998151 and parameters: {'units_l0': 176, 'dropout_l0': 0.11877882765646425, 'learning_rate': 0.00426401747618352, 'batch_size': 16, 'max_epochs': 55}. Best is trial 5 with value: 0.09154226717998151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.19509815982152867), np.float64(0.03446875873774213), np.float64(0.12253961292613212), np.float64(0.014062537234523085)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/79\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.1155 - val_loss: 0.0645\n",
      "Epoch 2/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 0.0326 - val_loss: 0.0487\n",
      "Epoch 3/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.0167 - val_loss: 0.1256\n",
      "Epoch 4/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.0133 - val_loss: 0.0697\n",
      "Epoch 5/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0139 - val_loss: 0.0463\n",
      "Epoch 6/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.0157 - val_loss: 0.0819\n",
      "Epoch 7/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0114 - val_loss: 0.0917\n",
      "Epoch 8/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.0089 - val_loss: 0.0575\n",
      "Epoch 9/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - loss: 0.0135 - val_loss: 0.0674\n",
      "Epoch 10/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - loss: 0.0089 - val_loss: 0.0884\n",
      "Epoch 11/79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0084 - val_loss: 0.0753\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/79\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0571 - val_loss: 0.0108\n",
      "Epoch 2/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0272 - val_loss: 0.0316\n",
      "Epoch 3/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0261 - val_loss: 0.0299\n",
      "Epoch 4/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0176 - val_loss: 0.0096\n",
      "Epoch 5/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0176 - val_loss: 0.0253\n",
      "Epoch 6/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 7/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0151 - val_loss: 0.0190\n",
      "Epoch 8/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0126 - val_loss: 0.0188\n",
      "Epoch 9/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 10/79\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0116 - val_loss: 0.0212\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/79\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1523"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0868 - val_loss: 0.1404\n",
      "Epoch 2/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0278 - val_loss: 0.0827\n",
      "Epoch 3/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0192 - val_loss: 0.0590\n",
      "Epoch 4/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0136 - val_loss: 0.0767\n",
      "Epoch 5/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0146 - val_loss: 0.0458\n",
      "Epoch 6/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0141 - val_loss: 0.0671\n",
      "Epoch 7/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0102 - val_loss: 0.0908\n",
      "Epoch 8/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0122 - val_loss: 0.1312\n",
      "Epoch 9/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0146 - val_loss: 0.1549\n",
      "Epoch 10/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0100 - val_loss: 0.2381\n",
      "Epoch 11/79\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0151 - val_loss: 0.2327\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Epoch 1/79\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - loss: 0.0451 - val_loss: 0.0030\n",
      "Epoch 2/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0193 - val_loss: 0.0018\n",
      "Epoch 3/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0124 - val_loss: 4.9455e-04\n",
      "Epoch 4/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0145 - val_loss: 0.0057\n",
      "Epoch 5/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0118 - val_loss: 0.0033\n",
      "Epoch 6/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0158 - val_loss: 0.0051\n",
      "Epoch 7/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0115 - val_loss: 0.0043\n",
      "Epoch 8/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0145 - val_loss: 0.0023\n",
      "Epoch 9/79\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0103 - val_loss: 0.0011\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:57:25,081] Trial 6 finished with value: 0.13740069275487174 and parameters: {'units_l0': 102, 'dropout_l0': 0.4109236150800367, 'learning_rate': 0.0023143364397181245, 'batch_size': 32, 'max_epochs': 79}. Best is trial 5 with value: 0.09154226717998151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.21512059252385463), np.float64(0.09814777193240642), np.float64(0.21409590342818738), np.float64(0.02223850313503848)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/47\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.1576 - val_loss: 0.0030\n",
      "Epoch 2/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.1526 - val_loss: 0.0023\n",
      "Epoch 3/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.1500 - val_loss: 0.0019\n",
      "Epoch 4/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.1305 - val_loss: 0.0018\n",
      "Epoch 5/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.1245 - val_loss: 0.0021\n",
      "Epoch 6/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 0.1087 - val_loss: 0.0026\n",
      "Epoch 7/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.1080 - val_loss: 0.0035\n",
      "Epoch 8/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.1063 - val_loss: 0.0046\n",
      "Epoch 9/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.1083 - val_loss: 0.0060\n",
      "Epoch 10/47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0899 - val_loss: 0.0077\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 1/47\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.1608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.1794 - val_loss: 0.0189\n",
      "Epoch 2/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1801 - val_loss: 0.0141\n",
      "Epoch 3/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.1783 - val_loss: 0.0102\n",
      "Epoch 4/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1423 - val_loss: 0.0072\n",
      "Epoch 5/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.1384 - val_loss: 0.0051\n",
      "Epoch 6/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1222 - val_loss: 0.0038\n",
      "Epoch 7/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1207 - val_loss: 0.0033\n",
      "Epoch 8/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.1169 - val_loss: 0.0035\n",
      "Epoch 9/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.1161 - val_loss: 0.0043\n",
      "Epoch 10/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0930 - val_loss: 0.0057\n",
      "Epoch 11/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0984 - val_loss: 0.0075\n",
      "Epoch 12/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0896 - val_loss: 0.0096\n",
      "Epoch 13/47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0861 - val_loss: 0.0121\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/47\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1094 - val_loss: 0.0251\n",
      "Epoch 2/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1035 - val_loss: 0.0157\n",
      "Epoch 3/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1029 - val_loss: 0.0101\n",
      "Epoch 4/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0921 - val_loss: 0.0072\n",
      "Epoch 5/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0846 - val_loss: 0.0058\n",
      "Epoch 6/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0733 - val_loss: 0.0056\n",
      "Epoch 7/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0762 - val_loss: 0.0061\n",
      "Epoch 8/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0660 - val_loss: 0.0068\n",
      "Epoch 9/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0625 - val_loss: 0.0076\n",
      "Epoch 10/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0591 - val_loss: 0.0083\n",
      "Epoch 11/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - loss: 0.0555 - val_loss: 0.0088\n",
      "Epoch 12/47\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - loss: 0.0574 - val_loss: 0.0093\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 277ms/step - loss: 0.0503 - val_loss: 0.0252\n",
      "Epoch 2/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 0.0461 - val_loss: 0.0180\n",
      "Epoch 3/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0471 - val_loss: 0.0160\n",
      "Epoch 4/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - loss: 0.0483 - val_loss: 0.0154\n",
      "Epoch 5/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0441 - val_loss: 0.0150\n",
      "Epoch 6/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0425 - val_loss: 0.0153\n",
      "Epoch 7/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0392 - val_loss: 0.0141\n",
      "Epoch 8/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0337 - val_loss: 0.0126\n",
      "Epoch 9/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0373 - val_loss: 0.0125\n",
      "Epoch 10/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0345 - val_loss: 0.0129\n",
      "Epoch 11/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - loss: 0.0254 - val_loss: 0.0124\n",
      "Epoch 12/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0276 - val_loss: 0.0123\n",
      "Epoch 13/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - loss: 0.0318 - val_loss: 0.0121\n",
      "Epoch 14/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0257 - val_loss: 0.0111\n",
      "Epoch 15/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0259 - val_loss: 0.0097\n",
      "Epoch 16/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - loss: 0.0275 - val_loss: 0.0087\n",
      "Epoch 17/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260ms/step - loss: 0.0233 - val_loss: 0.0087\n",
      "Epoch 18/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0197 - val_loss: 0.0083\n",
      "Epoch 19/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255ms/step - loss: 0.0179 - val_loss: 0.0084\n",
      "Epoch 20/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0205 - val_loss: 0.0084\n",
      "Epoch 21/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0216 - val_loss: 0.0074\n",
      "Epoch 22/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0169 - val_loss: 0.0067\n",
      "Epoch 23/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0200 - val_loss: 0.0067\n",
      "Epoch 24/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0188 - val_loss: 0.0061\n",
      "Epoch 25/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 0.0190 - val_loss: 0.0055\n",
      "Epoch 26/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0160 - val_loss: 0.0052\n",
      "Epoch 27/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - loss: 0.0183 - val_loss: 0.0051\n",
      "Epoch 28/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - loss: 0.0163 - val_loss: 0.0048\n",
      "Epoch 29/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0176 - val_loss: 0.0042\n",
      "Epoch 30/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - loss: 0.0126 - val_loss: 0.0035\n",
      "Epoch 31/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - loss: 0.0175 - val_loss: 0.0033\n",
      "Epoch 32/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - loss: 0.0177 - val_loss: 0.0038\n",
      "Epoch 33/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255ms/step - loss: 0.0149 - val_loss: 0.0039\n",
      "Epoch 34/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0154 - val_loss: 0.0035\n",
      "Epoch 35/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0151 - val_loss: 0.0034\n",
      "Epoch 36/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - loss: 0.0198 - val_loss: 0.0034\n",
      "Epoch 37/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0136 - val_loss: 0.0032\n",
      "Epoch 38/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0156 - val_loss: 0.0030\n",
      "Epoch 39/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0131 - val_loss: 0.0031\n",
      "Epoch 40/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0179 - val_loss: 0.0035\n",
      "Epoch 41/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0140 - val_loss: 0.0033\n",
      "Epoch 42/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0126 - val_loss: 0.0028\n",
      "Epoch 43/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0127 - val_loss: 0.0023\n",
      "Epoch 44/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - loss: 0.0133 - val_loss: 0.0025\n",
      "Epoch 45/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.0133 - val_loss: 0.0029\n",
      "Epoch 46/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0152 - val_loss: 0.0031\n",
      "Epoch 47/47\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 261ms/step - loss: 0.0145 - val_loss: 0.0028\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:59:07,356] Trial 7 finished with value: 0.05587022588862627 and parameters: {'units_l0': 97, 'dropout_l0': 0.40120937242275817, 'learning_rate': 2.9581099466973697e-05, 'batch_size': 64, 'max_epochs': 47}. Best is trial 7 with value: 0.05587022588862627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.04275741987345467), np.float64(0.05771589329975843), np.float64(0.07473612636577945), np.float64(0.04827146401551254)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step - loss: 1.0430 - val_loss: 0.0145\n",
      "Epoch 2/49\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - loss: 0.1239 - val_loss: 0.0123\n",
      "Epoch 3/49\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step - loss: 0.1308 - val_loss: 0.1291\n",
      "Epoch 4/49\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step - loss: 0.0394 - val_loss: 0.2549\n",
      "Epoch 5/49\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step - loss: 0.0524 - val_loss: 0.0807\n",
      "Epoch 6/49\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - loss: 0.0154 - val_loss: 0.0323\n",
      "Epoch 7/49\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step - loss: 0.0274 - val_loss: 0.0295\n",
      "Epoch 8/49\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - loss: 0.0270 - val_loss: 0.0512\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 1.4581 - val_loss: 0.0189\n",
      "Epoch 2/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 0.0945 - val_loss: 0.1357\n",
      "Epoch 3/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - loss: 0.0458 - val_loss: 0.0091\n",
      "Epoch 4/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0384 - val_loss: 0.0299\n",
      "Epoch 5/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - loss: 0.0228 - val_loss: 0.0624\n",
      "Epoch 6/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 0.0232 - val_loss: 0.0246\n",
      "Epoch 7/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - loss: 0.0182 - val_loss: 0.0102\n",
      "Epoch 8/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 0.0222 - val_loss: 0.0258\n",
      "Epoch 9/49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0214 - val_loss: 0.0402\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260ms/step - loss: 1.0792 - val_loss: 0.0047\n",
      "Epoch 2/49\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251ms/step - loss: 0.0513 - val_loss: 0.0075\n",
      "Epoch 3/49\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - loss: 0.0351 - val_loss: 0.0250\n",
      "Epoch 4/49\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 277ms/step - loss: 0.0211 - val_loss: 0.0798\n",
      "Epoch 5/49\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - loss: 0.0180 - val_loss: 0.0395\n",
      "Epoch 6/49\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - loss: 0.0148 - val_loss: 0.0875\n",
      "Epoch 7/49\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 229ms/step - loss: 0.0130 - val_loss: 0.0494\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 274ms/step - loss: 0.9463 - val_loss: 0.0913\n",
      "Epoch 2/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - loss: 0.0494 - val_loss: 0.0013\n",
      "Epoch 3/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0300 - val_loss: 0.0281\n",
      "Epoch 4/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0186 - val_loss: 0.0018\n",
      "Epoch 5/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - loss: 0.0184 - val_loss: 0.0097\n",
      "Epoch 6/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 294ms/step - loss: 0.0151 - val_loss: 6.7191e-04\n",
      "Epoch 7/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 278ms/step - loss: 0.0166 - val_loss: 0.0028\n",
      "Epoch 8/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step - loss: 0.0128 - val_loss: 4.3607e-04\n",
      "Epoch 9/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0131 - val_loss: 0.0021\n",
      "Epoch 10/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0104 - val_loss: 0.0031\n",
      "Epoch 11/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0131 - val_loss: 0.0024\n",
      "Epoch 12/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0137 - val_loss: 0.0018\n",
      "Epoch 13/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0122 - val_loss: 7.5506e-04\n",
      "Epoch 14/49\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0115 - val_loss: 0.0013\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 12:59:59,333] Trial 8 finished with value: 0.07397600108701058 and parameters: {'units_l0': 150, 'dropout_l0': 0.39775899903329787, 'learning_rate': 0.008768753056916418, 'batch_size': 64, 'max_epochs': 49}. Best is trial 7 with value: 0.05587022588862627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.11091500717660235), np.float64(0.09540273723580041), np.float64(0.06870390676502103), np.float64(0.020882353170618564)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/23\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1314 - val_loss: 0.2379\n",
      "Epoch 2/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0407 - val_loss: 0.0658\n",
      "Epoch 3/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0133 - val_loss: 0.0420\n",
      "Epoch 4/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0094 - val_loss: 0.0954\n",
      "Epoch 5/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0127 - val_loss: 0.0825\n",
      "Epoch 6/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0073 - val_loss: 0.0466\n",
      "Epoch 7/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0065 - val_loss: 0.0588\n",
      "Epoch 8/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0074 - val_loss: 0.0742\n",
      "Epoch 9/23\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0070 - val_loss: 0.0543\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 1/23\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.1018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0560 - val_loss: 0.0112\n",
      "Epoch 2/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 3/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 4/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 5/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 6/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0091 - val_loss: 0.0020\n",
      "Epoch 7/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 8/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 9/23\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Epoch 1/23\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.0863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0421 - val_loss: 0.0078\n",
      "Epoch 2/23\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0049 - val_loss: 0.0090\n",
      "Epoch 3/23\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0044 - val_loss: 0.0196\n",
      "Epoch 4/23\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0032 - val_loss: 0.0179\n",
      "Epoch 5/23\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0024 - val_loss: 0.0160\n",
      "Epoch 6/23\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0029 - val_loss: 0.0216\n",
      "Epoch 7/23\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0035 - val_loss: 0.0235\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Epoch 1/23\n",
      "\u001b[1m 2/28\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1799"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0584 - val_loss: 0.0029\n",
      "Epoch 2/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0061 - val_loss: 9.4762e-04\n",
      "Epoch 3/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0038 - val_loss: 9.2662e-04\n",
      "Epoch 4/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0027 - val_loss: 2.9060e-04\n",
      "Epoch 5/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0028 - val_loss: 4.2674e-04\n",
      "Epoch 6/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 0.0020 - val_loss: 5.6121e-04\n",
      "Epoch 7/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 8/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0016 - val_loss: 4.1528e-04\n",
      "Epoch 9/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0028 - val_loss: 2.3755e-04\n",
      "Epoch 10/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0021 - val_loss: 4.1535e-04\n",
      "Epoch 11/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0030 - val_loss: 2.4842e-04\n",
      "Epoch 12/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0019 - val_loss: 2.7445e-04\n",
      "Epoch 13/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0021 - val_loss: 3.3122e-04\n",
      "Epoch 14/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0022 - val_loss: 2.5763e-04\n",
      "Epoch 15/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0012 - val_loss: 2.3225e-04\n",
      "Epoch 16/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0012 - val_loss: 2.2156e-04\n",
      "Epoch 17/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0020 - val_loss: 6.4363e-04\n",
      "Epoch 18/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0022 - val_loss: 2.0000e-04\n",
      "Epoch 19/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0013 - val_loss: 3.1476e-04\n",
      "Epoch 20/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0027 - val_loss: 4.1363e-04\n",
      "Epoch 21/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0023 - val_loss: 6.3799e-04\n",
      "Epoch 22/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0015 - val_loss: 3.6526e-04\n",
      "Epoch 23/23\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0014 - val_loss: 6.8792e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 13:01:46,518] Trial 9 finished with value: 0.08687160878738175 and parameters: {'units_l0': 146, 'dropout_l0': 0.04649221889489896, 'learning_rate': 0.0003453594369753208, 'batch_size': 16, 'max_epochs': 23}. Best is trial 7 with value: 0.05587022588862627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.2049522725980285), np.float64(0.040349420398512637), np.float64(0.08804253332772677), np.float64(0.014142208825259097)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/95\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.2518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.2528 - val_loss: 0.0258\n",
      "Epoch 2/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.2721 - val_loss: 0.0249\n",
      "Epoch 3/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.2292 - val_loss: 0.0241\n",
      "Epoch 4/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.2414 - val_loss: 0.0232\n",
      "Epoch 5/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2461 - val_loss: 0.0224\n",
      "Epoch 6/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.2136 - val_loss: 0.0217\n",
      "Epoch 7/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.2627 - val_loss: 0.0209\n",
      "Epoch 8/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.2588 - val_loss: 0.0202\n",
      "Epoch 9/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.2430 - val_loss: 0.0194\n",
      "Epoch 10/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.2148 - val_loss: 0.0187\n",
      "Epoch 11/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.2122 - val_loss: 0.0180\n",
      "Epoch 12/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.2236 - val_loss: 0.0173\n",
      "Epoch 13/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.2091 - val_loss: 0.0167\n",
      "Epoch 14/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.2355 - val_loss: 0.0161\n",
      "Epoch 15/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.2314 - val_loss: 0.0154\n",
      "Epoch 16/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.2246 - val_loss: 0.0148\n",
      "Epoch 17/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.2261 - val_loss: 0.0142\n",
      "Epoch 18/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.2103 - val_loss: 0.0136\n",
      "Epoch 19/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.2309 - val_loss: 0.0131\n",
      "Epoch 20/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.1783 - val_loss: 0.0126\n",
      "Epoch 21/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.1807 - val_loss: 0.0120\n",
      "Epoch 22/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.2045 - val_loss: 0.0115\n",
      "Epoch 23/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.1960 - val_loss: 0.0111\n",
      "Epoch 24/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.1964 - val_loss: 0.0106\n",
      "Epoch 25/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.1845 - val_loss: 0.0101\n",
      "Epoch 26/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.2095 - val_loss: 0.0097\n",
      "Epoch 27/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.1873 - val_loss: 0.0092\n",
      "Epoch 28/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1811 - val_loss: 0.0088\n",
      "Epoch 29/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.2117 - val_loss: 0.0084\n",
      "Epoch 30/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1738 - val_loss: 0.0080\n",
      "Epoch 31/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.1734 - val_loss: 0.0076\n",
      "Epoch 32/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1643 - val_loss: 0.0073\n",
      "Epoch 33/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.1818 - val_loss: 0.0069\n",
      "Epoch 34/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.1828 - val_loss: 0.0066\n",
      "Epoch 35/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.1934 - val_loss: 0.0063\n",
      "Epoch 36/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.1606 - val_loss: 0.0060\n",
      "Epoch 37/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1656 - val_loss: 0.0057\n",
      "Epoch 38/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.1572 - val_loss: 0.0054\n",
      "Epoch 39/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.1640 - val_loss: 0.0052\n",
      "Epoch 40/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.1880 - val_loss: 0.0049\n",
      "Epoch 41/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.1798 - val_loss: 0.0047\n",
      "Epoch 42/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.1593 - val_loss: 0.0045\n",
      "Epoch 43/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.1684 - val_loss: 0.0043\n",
      "Epoch 44/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.1439 - val_loss: 0.0041\n",
      "Epoch 45/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 0.1699 - val_loss: 0.0039\n",
      "Epoch 46/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.1608 - val_loss: 0.0038\n",
      "Epoch 47/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.1726 - val_loss: 0.0036\n",
      "Epoch 48/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.1650 - val_loss: 0.0035\n",
      "Epoch 49/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.1524 - val_loss: 0.0034\n",
      "Epoch 50/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.1710 - val_loss: 0.0033\n",
      "Epoch 51/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.1424 - val_loss: 0.0032\n",
      "Epoch 52/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.1451 - val_loss: 0.0031\n",
      "Epoch 53/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.1514 - val_loss: 0.0030\n",
      "Epoch 54/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.1502 - val_loss: 0.0029\n",
      "Epoch 55/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.1266 - val_loss: 0.0029\n",
      "Epoch 56/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.1220 - val_loss: 0.0029\n",
      "Epoch 57/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.1391 - val_loss: 0.0028\n",
      "Epoch 58/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.1508 - val_loss: 0.0028\n",
      "Epoch 59/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.1427 - val_loss: 0.0028\n",
      "Epoch 60/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.1392 - val_loss: 0.0028\n",
      "Epoch 61/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.1321 - val_loss: 0.0028\n",
      "Epoch 62/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1268 - val_loss: 0.0028\n",
      "Epoch 63/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.1576 - val_loss: 0.0029\n",
      "Epoch 64/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.1295 - val_loss: 0.0029\n",
      "Epoch 65/95\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.1287 - val_loss: 0.0030\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/95\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.2158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.2485 - val_loss: 0.0162\n",
      "Epoch 2/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.2533 - val_loss: 0.0152\n",
      "Epoch 3/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.2655 - val_loss: 0.0142\n",
      "Epoch 4/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.2610 - val_loss: 0.0133\n",
      "Epoch 5/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.2347 - val_loss: 0.0125\n",
      "Epoch 6/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.2640 - val_loss: 0.0119\n",
      "Epoch 7/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2624 - val_loss: 0.0113\n",
      "Epoch 8/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.2311 - val_loss: 0.0108\n",
      "Epoch 9/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.2312 - val_loss: 0.0104\n",
      "Epoch 10/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.2229 - val_loss: 0.0100\n",
      "Epoch 11/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.2136 - val_loss: 0.0098\n",
      "Epoch 12/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2118 - val_loss: 0.0096\n",
      "Epoch 13/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2172 - val_loss: 0.0095\n",
      "Epoch 14/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.2083 - val_loss: 0.0095\n",
      "Epoch 15/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.2090 - val_loss: 0.0095\n",
      "Epoch 16/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.2148 - val_loss: 0.0096\n",
      "Epoch 17/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.2067 - val_loss: 0.0097\n",
      "Epoch 18/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1814 - val_loss: 0.0099\n",
      "Epoch 19/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1911 - val_loss: 0.0101\n",
      "Epoch 20/95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1813 - val_loss: 0.0104\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/95\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1077 - val_loss: 0.0398\n",
      "Epoch 2/95\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1171 - val_loss: 0.0418\n",
      "Epoch 3/95\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1066 - val_loss: 0.0434\n",
      "Epoch 4/95\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1026 - val_loss: 0.0446\n",
      "Epoch 5/95\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1078 - val_loss: 0.0461\n",
      "Epoch 6/95\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1072 - val_loss: 0.0474\n",
      "Epoch 7/95\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0987 - val_loss: 0.0487\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Epoch 1/95\n",
      "\u001b[1m2/7\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1492 - val_loss: 0.0016\n",
      "Epoch 2/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1464 - val_loss: 0.0012\n",
      "Epoch 3/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1276 - val_loss: 0.0011\n",
      "Epoch 4/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1225 - val_loss: 0.0010\n",
      "Epoch 5/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1234 - val_loss: 0.0011\n",
      "Epoch 6/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1133 - val_loss: 0.0014\n",
      "Epoch 7/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1168 - val_loss: 0.0017\n",
      "Epoch 8/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1179 - val_loss: 0.0021\n",
      "Epoch 9/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.1109 - val_loss: 0.0025\n",
      "Epoch 10/95\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0997 - val_loss: 0.0030\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 13:02:28,918] Trial 10 finished with value: 0.09546040415203776 and parameters: {'units_l0': 63, 'dropout_l0': 0.4840168865390681, 'learning_rate': 1.3465851818008535e-05, 'batch_size': 64, 'max_epochs': 95}. Best is trial 7 with value: 0.05587022588862627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.052902495730812425), np.float64(0.09724502248049867), np.float64(0.19958290850056765), np.float64(0.03211118989627234)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/32\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.4048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 0.3920 - val_loss: 0.0571\n",
      "Epoch 2/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 0.3665 - val_loss: 0.0466\n",
      "Epoch 3/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.3363 - val_loss: 0.0373\n",
      "Epoch 4/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.3049 - val_loss: 0.0290\n",
      "Epoch 5/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.2817 - val_loss: 0.0219\n",
      "Epoch 6/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.2593 - val_loss: 0.0158\n",
      "Epoch 7/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.2303 - val_loss: 0.0108\n",
      "Epoch 8/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.2052 - val_loss: 0.0068\n",
      "Epoch 9/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.1908 - val_loss: 0.0038\n",
      "Epoch 10/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.1857 - val_loss: 0.0018\n",
      "Epoch 11/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.1642 - val_loss: 7.7264e-04\n",
      "Epoch 12/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1347 - val_loss: 6.4744e-04\n",
      "Epoch 13/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.1331 - val_loss: 0.0014\n",
      "Epoch 14/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.1127 - val_loss: 0.0030\n",
      "Epoch 15/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1082 - val_loss: 0.0054\n",
      "Epoch 16/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0898 - val_loss: 0.0085\n",
      "Epoch 17/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0847 - val_loss: 0.0123\n",
      "Epoch 18/32\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0656 - val_loss: 0.0167\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 1/32\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.1436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1221 - val_loss: 0.0070\n",
      "Epoch 2/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.1039 - val_loss: 0.0097\n",
      "Epoch 3/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0780 - val_loss: 0.0148\n",
      "Epoch 4/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0733 - val_loss: 0.0222\n",
      "Epoch 5/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0520 - val_loss: 0.0311\n",
      "Epoch 6/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0425 - val_loss: 0.0408\n",
      "Epoch 7/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0449 - val_loss: 0.0505\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 1/32\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0855 - val_loss: 0.0056\n",
      "Epoch 2/32\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0798 - val_loss: 0.0070\n",
      "Epoch 3/32\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0472 - val_loss: 0.0126\n",
      "Epoch 4/32\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0437 - val_loss: 0.0195\n",
      "Epoch 5/32\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0400 - val_loss: 0.0254\n",
      "Epoch 6/32\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0396 - val_loss: 0.0273\n",
      "Epoch 7/32\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0370 - val_loss: 0.0259\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 1/32\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0509 - val_loss: 0.0046\n",
      "Epoch 2/32\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0346 - val_loss: 0.0125\n",
      "Epoch 3/32\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0330 - val_loss: 0.0185\n",
      "Epoch 4/32\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0329 - val_loss: 0.0179\n",
      "Epoch 5/32\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0287 - val_loss: 0.0145\n",
      "Epoch 6/32\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0309 - val_loss: 0.0110\n",
      "Epoch 7/32\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0246 - val_loss: 0.0095\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 13:02:49,015] Trial 11 finished with value: 0.06282630774099071 and parameters: {'units_l0': 120, 'dropout_l0': 0.23488660228701796, 'learning_rate': 4.117351054863275e-05, 'batch_size': 64, 'max_epochs': 32}. Best is trial 7 with value: 0.05587022588862627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.02544493159769638), np.float64(0.0837050853434097), np.float64(0.0746276403306988), np.float64(0.06752757369215792)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/12\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.2967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.2882 - val_loss: 0.0604\n",
      "Epoch 2/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.2520 - val_loss: 0.0487\n",
      "Epoch 3/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.2286 - val_loss: 0.0386\n",
      "Epoch 4/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.2074 - val_loss: 0.0301\n",
      "Epoch 5/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.1907 - val_loss: 0.0230\n",
      "Epoch 6/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.1580 - val_loss: 0.0175\n",
      "Epoch 7/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.1485 - val_loss: 0.0135\n",
      "Epoch 8/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.1328 - val_loss: 0.0109\n",
      "Epoch 9/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.1121 - val_loss: 0.0098\n",
      "Epoch 10/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1007 - val_loss: 0.0099\n",
      "Epoch 11/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0833 - val_loss: 0.0113\n",
      "Epoch 12/12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0707 - val_loss: 0.0139\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/12\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0756 - val_loss: 0.0164\n",
      "Epoch 2/12\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0557 - val_loss: 0.0314\n",
      "Epoch 3/12\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0453 - val_loss: 0.0473\n",
      "Epoch 4/12\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0402 - val_loss: 0.0613\n",
      "Epoch 5/12\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0369 - val_loss: 0.0697\n",
      "Epoch 6/12\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0346 - val_loss: 0.0697\n",
      "Epoch 7/12\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0336 - val_loss: 0.0652\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Epoch 1/12\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1741 - val_loss: 0.0120\n",
      "Epoch 2/12\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1230 - val_loss: 0.0070\n",
      "Epoch 3/12\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0857 - val_loss: 0.0113\n",
      "Epoch 4/12\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0598 - val_loss: 0.0225\n",
      "Epoch 5/12\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0481 - val_loss: 0.0368\n",
      "Epoch 6/12\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0479 - val_loss: 0.0485\n",
      "Epoch 7/12\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0443 - val_loss: 0.0558\n",
      "Epoch 8/12\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0402 - val_loss: 0.0575\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Epoch 1/12\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0675 - val_loss: 0.0409\n",
      "Epoch 2/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0571 - val_loss: 0.0409\n",
      "Epoch 3/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0543 - val_loss: 0.0365\n",
      "Epoch 4/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0503 - val_loss: 0.0304\n",
      "Epoch 5/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0400 - val_loss: 0.0229\n",
      "Epoch 6/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0347 - val_loss: 0.0192\n",
      "Epoch 7/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0308 - val_loss: 0.0183\n",
      "Epoch 8/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0294 - val_loss: 0.0185\n",
      "Epoch 9/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0255 - val_loss: 0.0140\n",
      "Epoch 10/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0225 - val_loss: 0.0088\n",
      "Epoch 11/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0193 - val_loss: 0.0075\n",
      "Epoch 12/12\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0163 - val_loss: 0.0091\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 13:03:13,052] Trial 12 finished with value: 0.09924066943449435 and parameters: {'units_l0': 119, 'dropout_l0': 0.22423016797074494, 'learning_rate': 5.738947075358359e-05, 'batch_size': 64, 'max_epochs': 12}. Best is trial 7 with value: 0.05587022588862627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_SCORES: [np.float64(0.09875159041525683), np.float64(0.1280790776951652), np.float64(0.08372497307706393), np.float64(0.08640703655049144)]\n",
      "TICKER SOLUSDT\n",
      "Epoch 1/36\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.7304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.7103 - val_loss: 0.3420\n",
      "Epoch 2/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.6123 - val_loss: 0.3298\n",
      "Epoch 3/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.6262 - val_loss: 0.3178\n",
      "Epoch 4/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.5721 - val_loss: 0.3062\n",
      "Epoch 5/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.5390 - val_loss: 0.2949\n",
      "Epoch 6/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.5436 - val_loss: 0.2840\n",
      "Epoch 7/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.5548 - val_loss: 0.2733\n",
      "Epoch 8/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.5680 - val_loss: 0.2628\n",
      "Epoch 9/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.5061 - val_loss: 0.2526\n",
      "Epoch 10/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.5126 - val_loss: 0.2427\n",
      "Epoch 11/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.4809 - val_loss: 0.2332\n",
      "Epoch 12/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.4596 - val_loss: 0.2240\n",
      "Epoch 13/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.4924 - val_loss: 0.2150\n",
      "Epoch 14/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.4552 - val_loss: 0.2063\n",
      "Epoch 15/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.4350 - val_loss: 0.1979\n",
      "Epoch 16/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.4705 - val_loss: 0.1897\n",
      "Epoch 17/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.4423 - val_loss: 0.1816\n",
      "Epoch 18/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.4399 - val_loss: 0.1738\n",
      "Epoch 19/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.3918 - val_loss: 0.1663\n",
      "Epoch 20/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.3903 - val_loss: 0.1591\n",
      "Epoch 21/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.4017 - val_loss: 0.1521\n",
      "Epoch 22/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.3632 - val_loss: 0.1453\n",
      "Epoch 23/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.3751 - val_loss: 0.1388\n",
      "Epoch 24/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.3324 - val_loss: 0.1325\n",
      "Epoch 25/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 0.3446 - val_loss: 0.1265\n",
      "Epoch 26/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.3428 - val_loss: 0.1206\n",
      "Epoch 27/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.3107 - val_loss: 0.1150\n",
      "Epoch 28/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2899 - val_loss: 0.1096\n",
      "Epoch 29/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2752 - val_loss: 0.1045\n",
      "Epoch 30/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.3030 - val_loss: 0.0995\n",
      "Epoch 31/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2987 - val_loss: 0.0946\n",
      "Epoch 32/36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2841 - val_loss: 0.0900\n",
      "Epoch 33/36\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-05-01 13:03:23,149] Trial 13 failed with parameters: {'units_l0': 52, 'dropout_l0': 0.22655432538037917, 'learning_rate': 3.929464630392763e-05, 'batch_size': 64, 'max_epochs': 36} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\2040832433.py\", line 25, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, fold_number=4),\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py\", line 67, in objective\n",
      "    model, scaler, history, (X_val, y_val) = train_lstm_for_asset(((X_train, X_val, y_train, y_val), scaler))\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ic2594\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py\", line 33, in train_lstm_for_asset\n",
      "    history = model.fit(\n",
      "              ^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 219, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 810, in __call__\n",
      "    return self._python_function(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 132, in multi_step_on_iterator\n",
      "    one_step_on_data(iterator.get_next())\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 810, in __call__\n",
      "    return self._python_function(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 113, in one_step_on_data\n",
      "    outputs = self.distribute_strategy.run(step_function, args=(data,))\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1673, in run\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 3263, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 4061, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 57, in train_step\n",
      "    y_pred = self(x, training=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 221, in call\n",
      "    return self._functional.call(inputs, training=training, mask=mask)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 183, in call\n",
      "    outputs = self._run_through_graph(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n",
      "    outputs = op(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 643, in call\n",
      "    return operation(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 584, in call\n",
      "    return super().call(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 408, in call\n",
      "    last_output, outputs, states = self.inner_loop(\n",
      "                                   ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 579, in inner_loop\n",
      "    return super().inner_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 348, in inner_loop\n",
      "    return backend.rnn(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 428, in rnn\n",
      "    final_outputs = tf.while_loop(\n",
      "                    ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 660, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py\", line 241, in while_loop_v2\n",
      "    return while_loop(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py\", line 488, in while_loop\n",
      "    loop_vars = body(*loop_vars)\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py\", line 479, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))\n",
      "                                 ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 411, in _step\n",
      "    output, new_states = step_function(\n",
      "                         ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 340, in step\n",
      "    output, new_states = self.cell(inputs, states, **cell_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 276, in call\n",
      "    inputs = inputs * dp_mask\n",
      "             ~~~~~~~^~~~~~~~~\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\override_binary_operator.py\", line 113, in binary_op_wrapper\n",
      "    return func(x, y, name=name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\tensor_math_operator_overrides.py\", line 76, in _mul_dispatch_factory\n",
      "    return math_ops._mul_dispatch(x, y, name=name)  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1748, in _mul_dispatch\n",
      "    return multiply(x, y, name=name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\", line 142, in wrapper\n",
      "    return op(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1260, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 526, in multiply\n",
      "    return gen_math_ops.mul(x, y, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6824, in mul\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-01 13:03:23,152] Trial 13 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14504\\2040832433.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m         study.optimize(lambda trial: objective(trial, fold_number=4),\n\u001b[32m     26\u001b[39m                     n_trials=\u001b[32m100\u001b[39m,\n\u001b[32m     27\u001b[39m                     timeout=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     28\u001b[39m                     callbacks=[stopping_condition])\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EarlyStoppingException:\n\u001b[32m     30\u001b[39m         print(\u001b[33m\"Study stopped early due to custom stopping condition.\"\u001b[39m)\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Retrieve the best hyperparameters\u001b[39;00m\n\u001b[32m     32\u001b[39m     best_params = study.best_params\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\optuna\\study\\study.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    471\u001b[39m         Raises:\n\u001b[32m    472\u001b[39m             RuntimeError:\n\u001b[32m    473\u001b[39m                 If nested invocation of this method occurs.\n\u001b[32m    474\u001b[39m         \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m         _optimize(\n\u001b[32m    476\u001b[39m             study=self,\n\u001b[32m    477\u001b[39m             func=func,\n\u001b[32m    478\u001b[39m             n_trials=n_trials,\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    115\u001b[39m                         )\n\u001b[32m    116\u001b[39m                     )\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    118\u001b[39m         study._thread_local.in_optimize_loop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m         progress_bar.close()\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m             \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m             \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m             \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m             \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n\u001b[32m    167\u001b[39m                 gc.collect()\n\u001b[32m    168\u001b[39m \n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    244\u001b[39m         frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m         \u001b[38;5;28;01mand\u001b[39;00m func_err \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(func_err, catch)\n\u001b[32m    247\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    244\u001b[39m         frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m         \u001b[38;5;28;01mand\u001b[39;00m func_err \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(func_err, catch)\n\u001b[32m    247\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14504\\2040832433.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         study.optimize(lambda trial: objective(trial, fold_number=4),\n\u001b[32m     26\u001b[39m                     n_trials=\u001b[32m100\u001b[39m,\n\u001b[32m     27\u001b[39m                     timeout=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     28\u001b[39m                     callbacks=[stopping_condition])\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(trial, fold_number)\u001b[39m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Use walkforward folds for training and validation\u001b[39;00m\n\u001b[32m     65\u001b[39m     rmse_scores = []\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, (X_train, X_val, y_train, y_val) \u001b[38;5;28;01min\u001b[39;00m enumerate(folds):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         model, scaler, history, (X_val, y_val) = train_lstm_for_asset(((X_train, X_val, y_train, y_val), scaler))\n\u001b[32m     68\u001b[39m         preds = model.predict(X_val).flatten()\n\u001b[32m     69\u001b[39m         rmse = np.sqrt(mean_squared_error(y_val, preds))\n\u001b[32m     70\u001b[39m         rmse_scores.append(rmse)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14504\\795467977.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(prepped_data, test_size)\u001b[39m\n\u001b[32m     29\u001b[39m     model.compile(optimizer=optimizer, loss=\u001b[33m'mean_squared_error'\u001b[39m)\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m     32\u001b[39m     es = EarlyStopping(monitor=\u001b[33m'val_loss'\u001b[39m, patience=\u001b[32m6\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     history = model.fit(\n\u001b[32m     34\u001b[39m         X_train, y_train,\n\u001b[32m     35\u001b[39m         validation_data=(X_val, y_val),\n\u001b[32m     36\u001b[39m         epochs=MAX_EPOCHS,\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    367\u001b[39m             callbacks.on_epoch_begin(epoch)\n\u001b[32m    368\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m    369\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;28;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m                     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m                     logs = self.train_function(iterator)\n\u001b[32m    372\u001b[39m                     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m self.stop_training:\n\u001b[32m    374\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m function(iterator):\n\u001b[32m    216\u001b[39m             if isinstance(\n\u001b[32m    217\u001b[39m                 iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m             ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m                 opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m    220\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m StopIteration\n\u001b[32m    222\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    806\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwds):\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Implements PolymorphicFunction.__call__.\u001b[39;00m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m self._run_functions_eagerly:\n\u001b[32m    809\u001b[39m       \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(self._name, tf_function_call=\u001b[33m\"eager\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._python_function(*args, **kwds)\n\u001b[32m    811\u001b[39m \n\u001b[32m    812\u001b[39m     \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# place.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    128\u001b[39m         @tf.autograph.experimental.do_not_convert\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m multi_step_on_iterator(iterator):\n\u001b[32m    130\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    131\u001b[39m                 return tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m                     one_step_on_data(iterator.get_next())\n\u001b[32m    133\u001b[39m                 )\n\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m             \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    806\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwds):\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Implements PolymorphicFunction.__call__.\u001b[39;00m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m self._run_functions_eagerly:\n\u001b[32m    809\u001b[39m       \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(self._name, tf_function_call=\u001b[33m\"eager\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._python_function(*args, **kwds)\n\u001b[32m    811\u001b[39m \n\u001b[32m    812\u001b[39m     \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# place.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    110\u001b[39m         @tf.autograph.experimental.do_not_convert\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m one_step_on_data(data):\n\u001b[32m    112\u001b[39m             \u001b[33m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m             outputs = self.distribute_strategy.run(step_function, args=(data,))\n\u001b[32m    114\u001b[39m             outputs = reduce_per_replica(\n\u001b[32m    115\u001b[39m                 outputs,\n\u001b[32m    116\u001b[39m                 self.distribute_strategy,\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1669\u001b[39m       \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m       \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m       fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m           fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3259\u001b[39m     _require_cross_replica_or_default_context_extended(self)\n\u001b[32m   3260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3261\u001b[39m       kwargs = {}\n\u001b[32m   3262\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m self._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m self._call_for_each_replica(fn, args, kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m _call_for_each_replica(self, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(self._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     56\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._call_has_training_arg:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m                 y_pred = self(x, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     58\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m                 y_pred = self(x)\n\u001b[32m     60\u001b[39m             loss = self._compute_loss(\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    946\u001b[39m                 )\n\u001b[32m    947\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    948\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    950\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     55\u001b[39m                 call_fn,\n\u001b[32m     56\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     57\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m call(self, inputs, training=\u001b[38;5;28;01mNone\u001b[39;00m, mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._functional:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._functional.call(inputs, training=training, mask=mask)\n\u001b[32m    222\u001b[39m \n\u001b[32m    223\u001b[39m         \u001b[38;5;66;03m# Fallback: Just apply the layer sequence.\u001b[39;00m\n\u001b[32m    224\u001b[39m         \u001b[38;5;66;03m# This typically happens if `inputs` is a nested struct.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    179\u001b[39m             masks = tree.flatten(mask)\n\u001b[32m    180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m x, mask \u001b[38;5;28;01min\u001b[39;00m zip(inputs, masks):\n\u001b[32m    181\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m                     backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         outputs = self._run_through_graph(\n\u001b[32m    184\u001b[39m             inputs, operation_fn=\u001b[38;5;28;01mlambda\u001b[39;00m op: operation_fn(op, training=training)\n\u001b[32m    185\u001b[39m         )\n\u001b[32m    186\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    167\u001b[39m                 op = operation_fn(node.operation)\n\u001b[32m    168\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m call_fn \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    169\u001b[39m                     outputs = call_fn(op, *args, **kwargs)\n\u001b[32m    170\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m                     outputs = op(*args, **kwargs)\n\u001b[32m    172\u001b[39m \n\u001b[32m    173\u001b[39m                 \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    174\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;28;01min\u001b[39;00m zip(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    639\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m operation._call_has_training_arg\n\u001b[32m    640\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m training \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m         ):\n\u001b[32m    642\u001b[39m             kwargs[\u001b[33m\"training\"\u001b[39m] = training\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m operation(*args, **kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    946\u001b[39m                 )\n\u001b[32m    947\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    948\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    950\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     55\u001b[39m                 call_fn,\n\u001b[32m     56\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     57\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    583\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m call(self, sequences, initial_state=\u001b[38;5;28;01mNone\u001b[39;00m, mask=\u001b[38;5;28;01mNone\u001b[39;00m, training=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m         return super().call(\n\u001b[32m    585\u001b[39m             sequences, mask=mask, training=training, initial_state=initial_state\n\u001b[32m    586\u001b[39m         )\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    404\u001b[39m         self._maybe_config_dropout_masks(\n\u001b[32m    405\u001b[39m             self.cell, sequences[:, \u001b[32m0\u001b[39m, :], initial_state\n\u001b[32m    406\u001b[39m         )\n\u001b[32m    407\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m         last_output, outputs, states = self.inner_loop(\n\u001b[32m    409\u001b[39m             sequences=sequences,\n\u001b[32m    410\u001b[39m             initial_state=initial_state,\n\u001b[32m    411\u001b[39m             mask=mask,\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    575\u001b[39m                 \u001b[33m\"but cuDNN is not supported for this layer configuration \"\u001b[39m\n\u001b[32m    576\u001b[39m                 \u001b[33m\"with this backend. Pass use_cudnn='auto' to fallback \"\u001b[39m\n\u001b[32m    577\u001b[39m                 \u001b[33m\"to a non-cuDNN implementation.\"\u001b[39m\n\u001b[32m    578\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m         return super().inner_loop(\n\u001b[32m    580\u001b[39m             sequences, initial_state, mask=mask, training=training\n\u001b[32m    581\u001b[39m         )\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    344\u001b[39m \n\u001b[32m    345\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m tree.is_nested(initial_state):\n\u001b[32m    346\u001b[39m             initial_state = [initial_state]\n\u001b[32m    347\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m         return backend.rnn(\n\u001b[32m    349\u001b[39m             step,\n\u001b[32m    350\u001b[39m             sequences,\n\u001b[32m    351\u001b[39m             initial_state,\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[39m\n\u001b[32m    424\u001b[39m                     initial_states, flat_new_state\n\u001b[32m    425\u001b[39m                 )\n\u001b[32m    426\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m (time + \u001b[32m1\u001b[39m, output_ta_t) + tuple(new_states)\n\u001b[32m    427\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m             final_outputs = tf.while_loop(\n\u001b[32m    429\u001b[39m                 body=_step,\n\u001b[32m    430\u001b[39m                 loop_vars=(time, output_ta) + states,\n\u001b[32m    431\u001b[39m                 **while_loop_kwargs,\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    656\u001b[39m                   _call_location(), decorator_utils.get_qualified_name(func),\n\u001b[32m    657\u001b[39m                   func.__module__, arg_name, arg_value,\n\u001b[32m    658\u001b[39m                   \u001b[33m'in a future version'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[32m    659\u001b[39m                   (\u001b[33m'after %s'\u001b[39m % date), instructions)\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[39m\n\u001b[32m    237\u001b[39m   ...   print(sess.run(x_out).shape)\n\u001b[32m    238\u001b[39m   (\u001b[32m1000\u001b[39m, \u001b[32m100\u001b[39m)\n\u001b[32m    239\u001b[39m \n\u001b[32m    240\u001b[39m   \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m   return while_loop(\n\u001b[32m    242\u001b[39m       cond=cond,\n\u001b[32m    243\u001b[39m       body=body,\n\u001b[32m    244\u001b[39m       loop_vars=loop_vars,\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[39m\n\u001b[32m    484\u001b[39m \n\u001b[32m    485\u001b[39m       loop_var_structure = nest.map_structure(type_spec.type_spec_from_value,\n\u001b[32m    486\u001b[39m                                               list(loop_vars))\n\u001b[32m    487\u001b[39m       \u001b[38;5;28;01mwhile\u001b[39;00m cond(*loop_vars):\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m         loop_vars = body(*loop_vars)\n\u001b[32m    489\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(loop_vars, (list, tuple)):\n\u001b[32m    490\u001b[39m           packed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    491\u001b[39m           loop_vars = (loop_vars,)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(i, lv)\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m         body = \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (i + \u001b[32m1\u001b[39m, orig_body(*lv))\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(time, output_ta_t, *states)\u001b[39m\n\u001b[32m    407\u001b[39m                     Tuple: `(time + \u001b[32m1\u001b[39m,output_ta_t) + tuple(new_states)`\n\u001b[32m    408\u001b[39m                 \"\"\"\n\u001b[32m    409\u001b[39m                 current_input = tuple(ta.read(time) \u001b[38;5;28;01mfor\u001b[39;00m ta \u001b[38;5;28;01min\u001b[39;00m input_ta)\n\u001b[32m    410\u001b[39m                 current_input = tree.pack_sequence_as(inputs, current_input)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m                 output, new_states = step_function(\n\u001b[32m    412\u001b[39m                     current_input, tuple(states) + tuple(constants)\n\u001b[32m    413\u001b[39m                 )\n\u001b[32m    414\u001b[39m                 flat_new_state = tree.flatten(new_states)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(inputs, states)\u001b[39m\n\u001b[32m    336\u001b[39m             \u001b[38;5;66;03m# that would otherwise break PyTorch's autograd functionality\u001b[39;00m\n\u001b[32m    337\u001b[39m             \u001b[38;5;66;03m# by modifying tensors needed for gradient computation.\u001b[39;00m\n\u001b[32m    338\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m backend.backend() == \u001b[33m\"torch\"\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m self.stateful:\n\u001b[32m    339\u001b[39m                 states = tree.map_structure(ops.copy, states)\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m             output, new_states = self.cell(inputs, states, **cell_kwargs)\n\u001b[32m    341\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m tree.is_nested(new_states):\n\u001b[32m    342\u001b[39m                 new_states = [new_states]\n\u001b[32m    343\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m output, new_states\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    946\u001b[39m                 )\n\u001b[32m    947\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    948\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    950\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     55\u001b[39m                 call_fn,\n\u001b[32m     56\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     57\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, states, training)\u001b[39m\n\u001b[32m    272\u001b[39m             c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n\u001b[32m    273\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    274\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;28;01mand\u001b[39;00m \u001b[32m0.0\u001b[39m < self.dropout < \u001b[32m1.0\u001b[39m:\n\u001b[32m    275\u001b[39m                 dp_mask = self.get_dropout_mask(inputs)\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m                 inputs = inputs * dp_mask\n\u001b[32m    277\u001b[39m \n\u001b[32m    278\u001b[39m             z = ops.matmul(inputs, self.kernel)\n\u001b[32m    279\u001b[39m \n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\override_binary_operator.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[32m    111\u001b[39m         \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[32m    112\u001b[39m         x, y = maybe_promote_tensors(x, y)\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(x, y, name=name)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    115\u001b[39m         \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[32m    116\u001b[39m         \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[32m    117\u001b[39m         \u001b[38;5;66;03m# and the tensor.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\tensor_math_operator_overrides.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m     72\u001b[39m             name=name,\n\u001b[32m     73\u001b[39m         ),\n\u001b[32m     74\u001b[39m         dtypes.bool,\n\u001b[32m     75\u001b[39m     )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m math_ops._mul_dispatch(x, y, name=name)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m   1744\u001b[39m     new_vals = gen_sparse_ops.sparse_dense_cwise_mul(y.indices, y.values,\n\u001b[32m   1745\u001b[39m                                                      y.dense_shape, x, name)\n\u001b[32m   1746\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse_tensor.SparseTensor(y.indices, new_vals, y.dense_shape)\n\u001b[32m   1747\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1748\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m multiply(x, y, name=name)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m    143\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m    145\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m    522\u001b[39m \n\u001b[32m    523\u001b[39m    * InvalidArgumentError: When `x` \u001b[38;5;28;01mand\u001b[39;00m `y` have incompatible shapes \u001b[38;5;28;01mor\u001b[39;00m types.\n\u001b[32m    524\u001b[39m   \"\"\"\n\u001b[32m    525\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops.mul(x, y, name)\n",
      "\u001b[32mc:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m   6825\u001b[39m         _ctx, \u001b[33m\"Mul\"\u001b[39m, name, x, y)\n\u001b[32m   6826\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   6827\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   6828\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m6829\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   6830\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   6831\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   6832\u001b[39m       return mul_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for ticker in assets:\n",
    "    if ticker in results.keys():\n",
    "        continue\n",
    "\n",
    "    print(f\"ENGINEERING {ticker}\")\n",
    "\n",
    "    # 4a) Load & feature-engineer\n",
    "    df = data.load_asset(ticker, sampling='1d')\n",
    "    df = data.add_fear_and_greed(df)\n",
    "    df = add_technical_features(df)\n",
    "    df = df[(df.index >= '2022-01-01') & (df.index <= '2023-12-31')]\n",
    "\n",
    "    # 4b) Train the LSTM\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    def stopping_condition(study, trial):\n",
    "        print(f\"TICKER {ticker}\")\n",
    "        if study.best_value is not None and study.best_value < 0.045:\n",
    "            print(f\"Early stopping as the best score {study.best_value:.6f} is below 0.002\")\n",
    "            raise EarlyStoppingException()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        study.optimize(lambda trial: objective(trial, fold_number=4),\n",
    "                    n_trials=100,\n",
    "                    timeout=None,\n",
    "                    callbacks=[stopping_condition])\n",
    "    except EarlyStoppingException:\n",
    "        print(\"Study stopped early due to custom stopping condition.\")\n",
    "    # Retrieve the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters for {ticker}: {best_params}\")\n",
    "\n",
    "    # Update global hyperparameters with the best ones\n",
    "    UNITS_L0 = best_params['units_l0']\n",
    "    DROPOUT_L0 = best_params['dropout_l0']\n",
    "    LEARNING_RATE = best_params['learning_rate']\n",
    "    BATCH_SIZE = best_params['batch_size']\n",
    "    MAX_EPOCHS = best_params['max_epochs']\n",
    "\n",
    "    # Train the LSTM with the best hyperparameters\n",
    "    folds, (X_final_test, y_final_test), scaler = prep_data(df, sequence_length=30, test_size=0.2, num_folds=4)\n",
    "    (X_train, X_val, y_train, y_val) = folds[-1]\n",
    "    X_train = np.concatenate((X_train, X_val), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_val), axis=0)\n",
    "    model, scaler, history, (X_val, y_val) = train_lstm_for_asset(((X_train, X_final_test, y_train, y_final_test), scaler))\n",
    "\n",
    "    # 4c) Save model and scaler\n",
    "    model_path  = f'models/WF_{ticker}_lstm_model.h5'\n",
    "    scaler_path = f'scalers/WF_{ticker}_scaler.pkl'\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "\n",
    "    # 4d) Store paths and validation data\n",
    "    results[ticker] = {\n",
    "        'model_path':  model_path,\n",
    "        'scaler_path': scaler_path,\n",
    "        'history':     history,\n",
    "        'X_val':       X_final_test,\n",
    "        'y_val':       y_final_test\n",
    "    }\n",
    "\n",
    "# 5. Compute and print validation RMSE for each asset\n",
    "for ticker, res in results.items():\n",
    "    # Load model (if not in memory) and validation data\n",
    "    model = load_model(res['model_path'])\n",
    "    X_val = res['X_val']\n",
    "    y_val = res['y_val']\n",
    "\n",
    "    # Predict and score\n",
    "    preds = model.predict(X_val).flatten()\n",
    "    rmse  = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    print(f\"{ticker} validation RMSE (scaled): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ic2594\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Stored 'test_predictions' (dict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/test_predictions.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = {}\n",
    "\n",
    "for ticker, res in results.items():\n",
    "    model = load_model(res['model_path'])\n",
    "    # Predict on the test set\n",
    "    preds = model.predict(res['X_val']).flatten()\n",
    "    dates = df.index[-len(preds):]  # Get the corresponding dates\n",
    "    test_predictions[ticker] = pd.Series(preds, index=dates)\n",
    "\n",
    "# Now `test_predictions` contains the predictions for each ticker indexed by date\n",
    "%store test_predictions\n",
    "joblib.dump(test_predictions, \"models/test_predictions.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
